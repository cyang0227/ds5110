{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "44172b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "ETL: Filter SEC companyfacts from 2017 to current year of SP500 companies.\n",
    "--------------------------------------------------------------------------\n",
    "This script uses DuckDB as a faster, im-memory query engine.\n",
    "No .duckdb file is created on disk.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import duckdb\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "371a9cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============== Environment Setup ===============\n",
    "RAW_COMPANYFACTS_PATH = \"../../../data/raw/sec_filing/companyfacts.csv\"\n",
    "SP500_CSV = \"../../../data/raw/S&P500.csv\"\n",
    "MAPPING_PATH = \"../../../data/raw/sec_filing/SP500_cik_mapping.csv\"\n",
    "OUTPUT_DIR = \"../../../data/raw/fundamentals/\"\n",
    "FILTER_START_DATE = \"2017-01-01\"\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f00f6fbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched 504 out of 504 companies with CIK.\n"
     ]
    }
   ],
   "source": [
    "# Load and merge SP500 and CIK mapping\n",
    "sp500 = pd.read_csv(SP500_CSV)\n",
    "cik_mapping = pd.read_csv(MAPPING_PATH)\n",
    "\n",
    "# Normalize column names\n",
    "sp500.columns = [col.strip().lower() for col in sp500.columns]\n",
    "cik_mapping.columns = [col.strip().lower() for col in cik_mapping.columns]\n",
    "\n",
    "# Merge to add cik\n",
    "sp500_merged = sp500.merge(cik_mapping, on=\"symbol\", how=\"left\")\n",
    "\n",
    "matched = sp500_merged[\"cik\"].notna().sum()\n",
    "print(f\"Matched {matched} out of {len(sp500_merged)} companies with CIK.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "735cec9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in companyfacts:\n",
      "           name     type\n",
      "0      column00  VARCHAR\n",
      "1           cik  VARCHAR\n",
      "2    entityName  VARCHAR\n",
      "3   companyFact  VARCHAR\n",
      "4           end  VARCHAR\n",
      "5           val  VARCHAR\n",
      "6          accn  VARCHAR\n",
      "7            fy  VARCHAR\n",
      "8            fp  VARCHAR\n",
      "9          form  VARCHAR\n",
      "10        filed  VARCHAR\n",
      "11        units  VARCHAR\n"
     ]
    }
   ],
   "source": [
    "# =============== Connect to DuckDB ===============\n",
    "con = duckdb.connect(database=':memory:')\n",
    "con.execute(\"PRAGMA threads=8;\")\n",
    "\n",
    "con.register(\"sp500_df\", sp500_merged)\n",
    "con.execute(\"CREATE TEMP TABLE sp500 AS SELECT * FROM sp500_df;\")\n",
    "\n",
    "# =============== Stream-read companyfacts with DuckDB ===============\n",
    "con.execute(f\"\"\"\n",
    "    CREATE VIEW companyfacts AS\n",
    "    SELECT * FROM read_csv_auto(\n",
    "        '{RAW_COMPANYFACTS_PATH}',\n",
    "        ALL_VARCHAR=TRUE,\n",
    "        SAMPLE_SIZE=-1,\n",
    "        AUTO_DETECT=TRUE\n",
    "    );\n",
    "\"\"\")\n",
    "\n",
    "cols = con.execute(\"PRAGMA table_info('companyfacts');\").fetchdf()\n",
    "print(\"Columns in companyfacts:\")\n",
    "print(cols[[\"name\", \"type\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "91ce8abe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filter SQL preview:\n",
      " \n",
      "            SELECT *\n",
      "            FROM companyfacts cf JOIN sp500 s on CAST(cf.cik AS BIGINT) = CAST(s.cik AS BIGINT)\n",
      "            WHERE TRY_CAST(filed AS DATE) >= DATE '2017-01-01';\n",
      "             ...\n"
     ]
    }
   ],
   "source": [
    "cf_cols = [r[1].lower() for r in con.execute(\"PRAGMA table_info('companyfacts');\").fetchall()]\n",
    "\n",
    "# join by cik\n",
    "if \"cik\" not in cf_cols:\n",
    "    raise ValueError(\"CIK column not found in companyfacts data.\")\n",
    "\n",
    "join_sql = \"FROM companyfacts cf JOIN sp500 s on CAST(cf.cik AS BIGINT) = CAST(s.cik AS BIGINT)\"\n",
    "\n",
    "# detect date column\n",
    "date_col_candidates = [\"filed\", \"end\", \"period_end\", \"acceptance_datetime\"]\n",
    "date_col = next((c for c in date_col_candidates if c in cf_cols), None)\n",
    "if not date_col:\n",
    "    raise ValueError(\"No valid date column found (expected filed/end/period_end).\")\n",
    "\n",
    "filter_sql = f\"\"\"\n",
    "            SELECT *\n",
    "            {join_sql}\n",
    "            WHERE TRY_CAST({date_col} AS DATE) >= DATE '{FILTER_START_DATE}';\n",
    "            \"\"\"\n",
    "print(\"Filter SQL preview:\\n\", filter_sql[:300], \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "84dd4e1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a22cfbb700ff4d6c95789d54a7f0b699",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parquet successfully written to ../../../data/raw/fundamentals/\n"
     ]
    }
   ],
   "source": [
    "# =============== Export to Parquet ===============\n",
    "# con.execute(\"CREATE TEMP VIEW filtered AS \" + filter_sql)\n",
    "\n",
    "# Add derived year for partitioning\n",
    "con.execute(f\"\"\"\n",
    "    CREATE TEMP VIEW filtered_with_year AS\n",
    "    SELECT *,\n",
    "           STRFTIME(TRY_CAST({date_col} AS DATE), '%Y') AS year\n",
    "    FROM filtered;\n",
    "\"\"\")\n",
    "\n",
    "# Partition by year and symbol if available\n",
    "partition_cols = [\"year\"]\n",
    "if \"symbol\" in sp500_merged.columns:\n",
    "    partition_cols.append(\"symbol\")\n",
    "part_expr = \", \".join(partition_cols)\n",
    "\n",
    "# Export Parquet (no database saved)\n",
    "con.execute(f\"\"\"\n",
    "    COPY (SELECT * FROM filtered_with_year)\n",
    "    TO '{OUTPUT_DIR}'\n",
    "    (FORMAT PARQUET, PARTITION_BY ({part_expr}), COMPRESSION 'ZSTD');\n",
    "\"\"\")\n",
    "\n",
    "print(f\"Parquet successfully written to {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d452b1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============== Cleanup ===============\n",
    "con.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds5110",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
