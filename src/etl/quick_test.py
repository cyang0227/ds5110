"""
å¿«é€Ÿæµ‹è¯• - ä¸€åˆ†é’ŸéªŒè¯åŠŸèƒ½
"""

from fetch_sp500_prices_batch import SP500PriceFetcherBatch
import pandas as pd
from pathlib import Path

print("=" * 70)
print("å¿«é€Ÿæµ‹è¯•: æŠ“å–2024å¹´10æœˆçš„3åªè‚¡ç¥¨æ•°æ®")
print("=" * 70)

# åˆ›å»ºæŠ“å–å™¨
fetcher = SP500PriceFetcherBatch(
    start_date="2024-10-01",
    end_date="2024-10-31",
    data_dir="data_test"
)

# æµ‹è¯•3åªè‚¡ç¥¨
test_symbols = ['AAPL', 'MSFT', 'GOOGL']

print(f"\næµ‹è¯•è‚¡ç¥¨: {', '.join(test_symbols)}")
print(f"æ—¥æœŸèŒƒå›´: 2024-10-01 è‡³ 2024-10-31")
print(f"ä¿å­˜ä½ç½®: data_test/\n")

# æŠ“å–æ•°æ®
print("å¼€å§‹æŠ“å–...")
fetcher.collect_data(test_symbols, delay=0.5)

# ä¿å­˜æ•°æ®
print("\nä¿å­˜æ•°æ®...")
fetcher.save_all_data()

# éªŒè¯æ•°æ®
print("\n" + "=" * 70)
print("éªŒè¯ç»“æœ:")
print("=" * 70)

test_dir = Path("data_test/raw/prices/source=yahoo")
parquet_files = list(test_dir.rglob("*.parquet"))

if parquet_files:
    df = pd.read_parquet(parquet_files[0])
    
    print(f"\nâœ… æˆåŠŸæŠ“å–æ•°æ®!")
    print(f"   æ–‡ä»¶: {parquet_files[0].name}")
    print(f"   æ€»è®°å½•æ•°: {len(df)}")
    print(f"   è‚¡ç¥¨æ•°é‡: {df['symbol'].nunique()}")
    print(f"   æ—¥æœŸèŒƒå›´: {df['trade_date'].min()} ~ {df['trade_date'].max()}")
    
    print("\nğŸ“Š æ•°æ®é¢„è§ˆ (å‰5è¡Œ):")
    print(df.head().to_string())
    
    print("\n" + "=" * 70)
    print("âœ… æµ‹è¯•æˆåŠŸ!")
    print("=" * 70)
    print("\nä¸‹ä¸€æ­¥:")
    print("  1. æŸ¥çœ‹æµ‹è¯•æ•°æ®: data_test/raw/prices/source=yahoo/")
    print("  2. è¿è¡Œå®Œæ•´æµ‹è¯•: python test_fetch.py")
    print("  3. åˆ é™¤æµ‹è¯•æ•°æ®: rm -rf data_test/")
    print("  4. å¼€å§‹æ­£å¼æŠ“å–: python fetch_sp500_prices_batch.py")
    
else:
    print("\nâŒ æœªæ‰¾åˆ°æ•°æ®æ–‡ä»¶")
    print("è¯·æ£€æŸ¥æ—¥å¿—è¾“å‡ºäº†è§£åŸå› ")